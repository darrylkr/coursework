{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1502b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:09:04.580678Z",
     "start_time": "2022-05-26T15:09:02.263031Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2, mutual_info_classif\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.calibration import CalibratedClassifierCV\n",
    "\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "import os\n",
    "import ipaddress\n",
    "import re\n",
    "import favicon\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup\n",
    "import socket\n",
    "import requests\n",
    "from googlesearch import search\n",
    "import whois\n",
    "from datetime import date, datetime\n",
    "import time\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad28ae0e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:09:07.012519Z",
     "start_time": "2022-05-26T15:09:06.951503Z"
    }
   },
   "outputs": [],
   "source": [
    "def trainModel():\n",
    "    print(\"Initializing model training...\")\n",
    "    data = pd.read_csv(\"phishing_data.csv\", index_col=0)\n",
    "    \n",
    "    y = data['Result'].values\n",
    "    X = data.drop('Result',axis=1).values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state = 0)\n",
    "\n",
    "    k_folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)      #for gridsearch\n",
    "    k_folds2 = StratifiedKFold(n_splits=10, shuffle=True, random_state=100)  #for top50 pipeline cv\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    \n",
    "    #Logistic Regression\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    LR = LogisticRegression()\n",
    "\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('LR', LR)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14],    #we start with 4 because of our earlier discovery through visualisation of heatmap + feature ranking\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'LR__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'LR__penalty': ['l2'],\n",
    "        'LR__max_iter': [100, 200, 300],\n",
    "        'LR__solver': ['newton-cg', 'lbfgs', 'liblinear']\n",
    "    }\n",
    "\n",
    "    print(\"Training Logistic Regression Model... This can take up to over an hour\")\n",
    "    grid_search_LR = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1)\n",
    "    grid_search_LR.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "    \n",
    "    topFifty = grid_search_LR.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_LR.cv_results_['params']\n",
    "    highestScore = grid_search_LR.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "    \n",
    "    print(\"Cross Validating top fifty Logistic Regression pipelines...\")\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_LR.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']    \n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        C = params[i]['LR__C']\n",
    "        max_iter = params[i]['LR__max_iter']\n",
    "        penalty = params[i]['LR__penalty']\n",
    "        solver = params[i]['LR__solver']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        LR = LogisticRegression(C=C, max_iter=max_iter, penalty=penalty, solver=solver)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('LR', LR)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    LR_pipeline = pipelines[index]\n",
    "    LR_pipeline.fit(X_train, y_train)\n",
    "    LR_accuracy = LR_pipeline.score(X_test, y_test)\n",
    "    print(\"Finished training Logistic Regression Model. Preparing to train Naive Bayes model...\\n\")\n",
    "\n",
    "    # Naive Bayes\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    Bernoulli = BernoulliNB()\n",
    "\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('NB', Bernoulli)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4,5,6,7,8,9,10,11,12,13,14],\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'NB__alpha': [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]\n",
    "    }\n",
    "    \n",
    "    print(\"Training Naive Bayes Model... This can take up to half an hour.\")\n",
    "    grid_search_nb = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1)\n",
    "    grid_search_nb.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "    \n",
    "    topFifty = grid_search_nb.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_nb.cv_results_['params']\n",
    "    highestScore = grid_search_nb.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "\n",
    "    print(\"Cross Validating top fifty Naive Bayes pipelines...\")\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_nb.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']\n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        alpha = params[i]['NB__alpha']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        Bernoulli = BernoulliNB(alpha=alpha)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('NB', Bernoulli)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    NB_pipeline = pipelines[index]\n",
    "    NB_pipeline.fit(X_train, y_train)\n",
    "    NB_accuracy = NB_pipeline.score(X_test, y_test)\n",
    "    print(\"Finished training Naive Bayes Model. Preparing to train K-nearest Neighbors model...\\n\")\n",
    "\n",
    "    ## KNN\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    knn = KNeighborsClassifier()\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('KNN', knn)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4,5,6,7,8,9,10,11,12,13,14],\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'KNN__n_neighbors': [10,11,12,13,14,15],\n",
    "        'KNN__weights': ['uniform', 'distance']\n",
    "    }\n",
    "\n",
    "    print(\"Training K-nearest Neighbors Model... This can take up to half an hour.\")\n",
    "    grid_search_knn = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1) \n",
    "    grid_search_knn.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "    \n",
    "    topFifty = grid_search_knn.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_knn.cv_results_['params']\n",
    "    highestScore = grid_search_knn.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "\n",
    "    print(\"Cross Validating top fifty KNN pipelines...\")\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_knn.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']    \n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        n_neighbors = params[i]['KNN__n_neighbors']\n",
    "        weights = params[i]['KNN__weights']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('KNN', knn)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    knn_pipeline = pipelines[index]\n",
    "    knn_pipeline.fit(X_train, y_train)\n",
    "    knn_accuracy = knn_pipeline.score(X_test, y_test)\n",
    "    print(\"Finished training K-nearest Neighbors Model. Preparing to train Decision Tree model...\\n\")\n",
    "\n",
    "    #Decision Tree\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    dtree = DecisionTreeClassifier()\n",
    "\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('tree', dtree)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4,5,6,7,8,9,10,11,12,13,14],\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'tree__criterion' : ['gini', 'entropy'],\n",
    "        'tree__max_depth' : [None,5,10,15,20],\n",
    "        'tree__min_samples_split' : [2,5,10,15]\n",
    "    }\n",
    "\n",
    "    print(\"Training Decision Tree Model... This can take up to over an hour.\")\n",
    "    grid_search_dtree = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1) \n",
    "    grid_search_dtree.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "    \n",
    "    topFifty = grid_search_dtree.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_dtree.cv_results_['params']\n",
    "    highestScore = grid_search_dtree.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "\n",
    "    print(\"Cross Validating top fifty Decision Tree pipelines...\")\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_dtree.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']    \n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        criterion = params[i]['tree__criterion']\n",
    "        max_depth = params[i]['tree__max_depth']\n",
    "        min_samples_split = params[i]['tree__min_samples_split']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        dtree = DecisionTreeClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('tree', dtree)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    dtree_pipeline = pipelines[index]\n",
    "    dtree_pipeline.fit(X_train, y_train)\n",
    "    dtree_accuracy = dtree_pipeline.score(X_test, y_test)\n",
    "    print(\"Finished training Decision Tree Model. Preparing to train Random Forest model...\\n\")\n",
    "\n",
    "    # Random Forest\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    RF = RandomForestClassifier()\n",
    "\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('RF', RF)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4,5,6,7,8,9,10,11,12,13,14],\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'RF__criterion' : ['gini', 'entropy'],\n",
    "        'RF__max_depth' : [None,5,10,15,20,25],\n",
    "        'RF__min_samples_split' : [2, 5, 10],\n",
    "    }\n",
    "\n",
    "    print(\"Training Random Forest Model... This can take up to over an hour.\")\n",
    "    grid_search_RF = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1) \n",
    "    grid_search_RF.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "\n",
    "    print(\"Cross Validating top fifty Random Forest pipelines...\")\n",
    "    topFifty = grid_search_RF.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_RF.cv_results_['params']\n",
    "    highestScore = grid_search_RF.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_RF.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']    \n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        criterion = params[i]['RF__criterion']\n",
    "        max_depth = params[i]['RF__max_depth']\n",
    "        min_samples_split = params[i]['RF__min_samples_split']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        RF = RandomForestClassifier(criterion=criterion, max_depth=max_depth, min_samples_split=min_samples_split)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('RF', RF)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    RF_pipeline = pipelines[index]\n",
    "    RF_pipeline.fit(X_train, y_train)\n",
    "    RF_accuracy = RF_pipeline.score(X_test, y_test)\n",
    "    print(\"Finished training Random Forest Model. Preparing to train Support Vector Machine model...\\n\")\n",
    "\n",
    "    # SVM\n",
    "    scaler = MinMaxScaler()\n",
    "    kbest = SelectKBest()\n",
    "    svm = SVC()\n",
    "\n",
    "    pipeline = Pipeline([('scaler', scaler),\n",
    "                         ('kbest', kbest),\n",
    "                         ('svm', svm)])\n",
    "\n",
    "    param_grid = {\n",
    "        'kbest__k': [4,5,6,7,8,9,10,11,12,13,14],\n",
    "        'kbest__score_func': [chi2, mutual_info_classif],\n",
    "        'svm__C' : [0.001, 0.01, 0.1, 1, 10],\n",
    "        'svm__kernel': ['poly', 'rbf', 'sigmoid']\n",
    "    }\n",
    "\n",
    "    print(\"Training Support Vector Machine Model... This can take up to over an hour.\")\n",
    "    grid_search_svm = GridSearchCV(pipeline, param_grid=param_grid, cv=k_folds, scoring='accuracy', verbose=1) \n",
    "    grid_search_svm.fit(X_train, y_train)\n",
    "    print(\"Hyperparameter tuning complete.\")\n",
    "\n",
    "    topFifty = grid_search_svm.cv_results_['rank_test_score'].argsort()[:50]\n",
    "    params = grid_search_svm.cv_results_['params']\n",
    "    highestScore = grid_search_svm.best_score_\n",
    "\n",
    "    pipelines = []\n",
    "    accuracy_ = []\n",
    "    accuracy_std = []\n",
    "\n",
    "    print(\"Cross Validating top fifty Support Vector Machine pipelines...\")\n",
    "    for i in topFifty:\n",
    "        if (highestScore - grid_search_svm.cv_results_['mean_test_score'][i] >= 1):\n",
    "            break\n",
    "        k = params[i]['kbest__k']    \n",
    "        score_func = params[i]['kbest__score_func']    \n",
    "        C = params[i]['svm__C']\n",
    "        kernel = params[i]['svm__kernel']\n",
    "\n",
    "        kbest = SelectKBest(score_func=score_func, k=k)\n",
    "        svm = SVC(C=C, kernel=kernel)\n",
    "\n",
    "        pipeline = Pipeline([('scaler', scaler),\n",
    "                             ('kbest', kbest),\n",
    "                             ('svm', svm)])\n",
    "\n",
    "        accuracy = cross_val_score(pipeline, X_train, y_train, cv=k_folds2, scoring='accuracy')\n",
    "\n",
    "        pipelines.append(pipeline)\n",
    "        accuracy_.append(accuracy.mean())\n",
    "        accuracy_std.append(accuracy.std())\n",
    "\n",
    "    value = min(accuracy_std)\n",
    "    index = accuracy_std.index(value)\n",
    "    svm_pipeline = pipelines[index]\n",
    "    \n",
    "    #calibrated classifier calibrates SVM's decision_values() into average probabilites so that\n",
    "    #the predict_proba() method can be called using the SVM model. THis is needed later when we fit it in VotingClassifier()\n",
    "    svm_CCV = CalibratedClassifierCV(svm_pipeline, method='isotonic')\n",
    "    svm_CCV.fit(X_train, y_train)\n",
    "    svm_accuracy = svm_CCV.score(X_test, y_test)\n",
    "    print(\"Finished training Support Vector Machine Model. Finalizing modeling...\")\n",
    "    \n",
    "    models = []\n",
    "    scores = []\n",
    "    models.extend([LR_pipeline, NB_pipeline, knn_pipeline, dtree_pipeline, RF_pipeline])\n",
    "    scores.extend([LR_accuracy, NB_accuracy, knn_accuracy, dtree_accuracy, RF_accuracy, svm_accuracy])\n",
    "    \n",
    "    highestAccuracy = max(scores)\n",
    "    del scores[-1]\n",
    "    \n",
    "    toDelete = []\n",
    "    for i in range(len(scores)):\n",
    "        if highestAccuracy-scores[i] > 0.05:\n",
    "            toDelete.append(i)\n",
    "            \n",
    "    toDelete.reverse()\n",
    "    for i in toDelete:\n",
    "        del models[i]\n",
    "        \n",
    "    estimators = []\n",
    "    for model in models:\n",
    "        name = [*model.named_steps.keys()][-1]\n",
    "        clf = model\n",
    "        estimators.append((name,clf))\n",
    "    \n",
    "    estimators.append(('svm',svm_CCV))\n",
    "    \n",
    "    ensemble = VotingClassifier(estimators, voting='soft')\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    ensemble_accuracy = ensemble.score(X_test, y_test)\n",
    "    \n",
    "    models = []\n",
    "    scores = []\n",
    "    models.extend([LR_pipeline, NB_pipeline, knn_pipeline, dtree_pipeline, RF_pipeline, svm_CCV, ensemble])\n",
    "    scores.extend([LR_accuracy, NB_accuracy, knn_accuracy, dtree_accuracy, RF_accuracy, svm_accuracy, ensemble_accuracy])\n",
    "       \n",
    "    #refit on whole data set\n",
    "    finalModel = VotingClassifier(estimators, voting='soft')\n",
    "    finalModel.fit(X, y)\n",
    "    \n",
    "    modelDate = datetime.now().strftime(\"%d%m%Y_%H%M\")\n",
    "    filename = 'Ensemble_' + modelDate + '.sav'\n",
    "    pickle.dump(finalModel, open(filename, 'wb'))\n",
    "    \n",
    "    return finalModel, models, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "522c729d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:09:08.062552Z",
     "start_time": "2022-05-26T15:09:08.053550Z"
    }
   },
   "outputs": [],
   "source": [
    "def dataext(url):    \n",
    "    data = generate_data_set(url)\n",
    "    data = np.array(data)\n",
    "    data = data.reshape(1,-1)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b9aa904",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T15:09:08.188585Z",
     "start_time": "2022-05-26T15:09:08.158578Z"
    }
   },
   "outputs": [],
   "source": [
    "def generate_data_set(url):\n",
    "    \n",
    "    data_set = []\n",
    "    \n",
    "    # Converts the given URL into standard format\n",
    "    if not re.match(r\"^https?\", url):\n",
    "        url = \"https://\" + url\n",
    "        \n",
    "    # Stores the response of the given URL\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        responseCode = int(re.findall(r'[\\d]{3}',str(response))[0])\n",
    "        if (responseCode >= 400):\n",
    "            response = ''\n",
    "            soup = -999\n",
    "        else:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "    except:\n",
    "        response = \"\"\n",
    "        soup = -999\n",
    "        \n",
    "    # Extracts domain from the given URL\n",
    "    domain = re.findall(r\"://([^/]+)/?\", url)[0]\n",
    "    if re.match(r\"^www.\",domain):\n",
    "        domain = domain.replace(\"www.\",\"\")\n",
    "    \n",
    "    try:\n",
    "        whois_response = whois.whois(domain)\n",
    "    except:\n",
    "        whois_response = ''\n",
    "        \n",
    "    #1. having IP Address\n",
    "    try:\n",
    "        ipaddress.ip_address(url)\n",
    "        data_set.append(-1)\n",
    "    except:\n",
    "        data_set.append(1) \n",
    "        \n",
    "    # 2.URL_Length\n",
    "    if len(url) < 54:\n",
    "        data_set.append(1)\n",
    "    elif len(url) >= 54 and len(url) <= 75:\n",
    "        data_set.append(0)\n",
    "    else:\n",
    "        data_set.append(-1)\n",
    "        \n",
    "    # 3.Shortining_Service\n",
    "    match=re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n",
    "                    'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n",
    "                    'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n",
    "                    'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n",
    "                    'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n",
    "                    'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n",
    "                    'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|tr\\.im|link\\.zip\\.net', url)\n",
    "    if match:\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        data_set.append(1)\n",
    "    \n",
    "    #4. having_At_Symbol\n",
    "    if re.findall(\"@\", url):\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        data_set.append(1)\n",
    "    \n",
    "    #5. Prefix_Suffix\n",
    "    if re.findall(r\"https?://[^/-]+-[^/-]+/?\", url):\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        data_set.append(1)\n",
    "        \n",
    "    # 6.having_Sub_Domain\n",
    "    if len(re.findall(\"\\.\", domain)) == 1:\n",
    "        data_set.append(1)\n",
    "    elif len(re.findall(\"\\.\", domain)) == 2:\n",
    "        data_set.append(0)\n",
    "    else:\n",
    "        data_set.append(-1)\n",
    "        \n",
    "    # 7.SSLfinal_State\n",
    "    if response == '':\n",
    "        httpUrl=[x.start(0) for x in re.finditer('://', url)]\n",
    "    else:\n",
    "        httpUrl=[x.start(0) for x in re.finditer('://', response.url)]\n",
    "        \n",
    "    if httpUrl[0]>4:\n",
    "        data_set.append(1)\n",
    "    else:\n",
    "        data_set.append(-1)\n",
    "        \n",
    "    # 8.Favicon\n",
    "    try:\n",
    "        icons = favicon.get(url)\n",
    "        if len(icons) == 0:\n",
    "            data_set.append(-1)\n",
    "        else:\n",
    "            data_set.append(1)\n",
    "    except:\n",
    "        data_set.append(-1)\n",
    "        \n",
    "    #9. HTTPS_token\n",
    "    if re.findall(r\"https\", domain):\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        data_set.append(1)\n",
    "            \n",
    "    #10. Iframe\n",
    "    if response == \"\":\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        hiddenBorders = False\n",
    "        for iframe in soup.find_all('iframe'):\n",
    "            if re.search(r'style', str(iframe)):\n",
    "                iframeStyle = iframe\n",
    "                if re.findall(r\"border ?: ?0\", str(iframeStyle) or re.findall(r\"border ?: ?none\", str(iframeStyle))):\n",
    "                    hiddenBorders = True\n",
    "        \n",
    "        if hiddenBorders == True:\n",
    "            data_set.append(-1)\n",
    "        else:\n",
    "            data_set.append(1)\n",
    "               \n",
    "    #11. age_of_domain\n",
    "    try:\n",
    "        if whois_response == '':\n",
    "            data_set.append(-1)\n",
    "        else:\n",
    "            if type(whois_response.creation_date) is list:\n",
    "                registration_date = whois_response.creation_date[0]\n",
    "            else:\n",
    "                registration_date = whois_response.creation_date\n",
    "\n",
    "            if diff_month(datetime.today(), registration_date) >= 6:\n",
    "                data_set.append(1)\n",
    "            else:\n",
    "                data_set.append(-1)\n",
    "    except:\n",
    "        data_set.append(-1)\n",
    "        \n",
    "    #12. web_traffic\n",
    "    try:\n",
    "        r = requests.get('http://tools.mercenie.com/alexa-rank-checker/api/?format=json&urls=' + url)\n",
    "        rCode = int(re.findall(r'[\\d]{3}',str(r))[0])\n",
    "        if (rCode >= 400):\n",
    "            data_set.append(-1)\n",
    "        else:\n",
    "            data = r.json()\n",
    "            rank = data['alexaranks']['first']['alexarank']['0']\n",
    "            rank = int(rank)\n",
    "            \n",
    "            if (rank<100000):\n",
    "                data_set.append(1)\n",
    "            elif (rank>100000):\n",
    "                data_set.append(0)\n",
    "            else:\n",
    "                data_set.append(-1)\n",
    "    except:\n",
    "        data_set.append(-1)\n",
    "    \n",
    "    #13. Google_Index\n",
    "    try:\n",
    "        site = search(domain, 10)\n",
    "        resultInSite = False\n",
    "        for result in site:\n",
    "            if re.search(domain, result):\n",
    "                resultInSite = True            \n",
    "        if resultInSite:\n",
    "            data_set.append(1)\n",
    "        else:\n",
    "            data_set.append(-1)\n",
    "    except:\n",
    "        data_set.append(-1)\n",
    "    \n",
    "    #14. Links_pointing_to_page\n",
    "    if response == \"\":\n",
    "        data_set.append(-1)\n",
    "    else:\n",
    "        number_of_links = len(re.findall(r\"<a href=\", response.text))\n",
    "        if number_of_links == 0:\n",
    "            data_set.append(-1)\n",
    "        elif number_of_links <= 2:\n",
    "            data_set.append(0)\n",
    "        elif number_of_links > 2:\n",
    "            data_set.append(1)\n",
    "    \n",
    "    return data_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b6476b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T12:53:23.424930Z",
     "start_time": "2022-05-26T12:53:23.391922Z"
    }
   },
   "outputs": [],
   "source": [
    "#model = pickle.load(open(\"Ensemble_26052022_0049.sav\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739968a9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T12:53:08.172608Z",
     "start_time": "2022-05-26T12:53:04.648033Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ensemble, models, accuracy = trainModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "22b33142",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T14:22:20.778601Z",
     "start_time": "2022-05-26T14:22:20.755450Z"
    }
   },
   "outputs": [],
   "source": [
    "realTestData = pd.read_csv(\"realData.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "aec71f9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T14:22:22.453563Z",
     "start_time": "2022-05-26T14:22:22.435512Z"
    }
   },
   "outputs": [],
   "source": [
    "X = realTestData['URLs'].values\n",
    "y_test = realTestData['Result'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f9e81c6b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T14:25:54.833546Z",
     "start_time": "2022-05-26T14:22:23.164034Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to connect to socket: closing socket\n",
      "Error trying to connect to socket: closing socket\n",
      "Error trying to connect to socket: closing socket\n",
      "Error trying to connect to socket: closing socket\n",
      "Error trying to connect to socket: closing socket\n"
     ]
    }
   ],
   "source": [
    "X_test = [generate_data_set(url) for url in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "bd235c78",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T14:29:23.031693Z",
     "start_time": "2022-05-26T14:29:22.972127Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Voter\n",
      "classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "          -1       1.00      0.30      0.46        30\n",
      "           1       0.59      1.00      0.74        30\n",
      "\n",
      "    accuracy                           0.65        60\n",
      "   macro avg       0.79      0.65      0.60        60\n",
      "weighted avg       0.79      0.65      0.60        60\n",
      "\n",
      "confusion matrix: \n",
      " [[ 9 21]\n",
      " [ 0 30]]\n",
      "accuracy score: \n",
      " 0.65\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "print('Ensemble Voter\\nclassification report: \\n', classification_report(y_test, pred))\n",
    "print('confusion matrix: \\n', confusion_matrix(y_test, pred))\n",
    "print('accuracy score: \\n', accuracy_score(y_test, pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
