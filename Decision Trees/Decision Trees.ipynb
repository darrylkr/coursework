{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:43.122034Z",
     "start_time": "2020-07-31T04:54:42.609291Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:43.713406Z",
     "start_time": "2020-07-31T04:54:43.632844Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28.7967,16.0021,2.6449,0.3918,0.1982,27.7004,22.011,-8.2027,40.092,81.8828,g\n",
      "31.6036,11.7235,2.5185,0.5303,0.3773,26.2722,23.8238,-9.9574,6.3609,205.261,g\n",
      "162.052,136.031,4.0612,0.0374,0.0187,116.741,-64.858,-45.216,76.96,256.788,g\n"
     ]
    }
   ],
   "source": [
    "!head -n 3 ./magic04.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:44.424882Z",
     "start_time": "2020-07-31T04:54:44.345064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Title of Database: MAGIC gamma telescope data 2004\n",
      "\n",
      "2. Sources:\n",
      "\n",
      "   (a) Original owner of the database:\n",
      "\n",
      "       R. K. Bock\n",
      "       Major Atmospheric Gamma Imaging Cherenkov Telescope project (MAGIC)\n",
      "       http://wwwmagic.mppmu.mpg.de\n",
      "       rkb@mail.cern.ch\n",
      "\n",
      "   (b) Donor:\n",
      "\n",
      "       P. Savicky\n",
      "       Institute of Computer Science, AS of CR\n",
      "       Czech Republic\n",
      "       savicky@cs.cas.cz\n",
      "\n",
      "   (c) Date received: May 2007\n",
      "\n",
      "3. Past Usage:\n",
      "\n",
      "   (a) Bock, R.K., Chilingarian, A., Gaug, M., Hakl, F., Hengstebeck, T.,\n",
      "       Jirina, M., Klaschka, J., Kotrc, E., Savicky, P., Towers, S.,\n",
      "       Vaicilius, A., Wittek W. (2004).\n",
      "       Methods for multidimensional event classification: a case study\n",
      "       using images from a Cherenkov gamma-ray telescope.\n",
      "       Nucl.Instr.Meth. A, 516, pp. 511-528.\n",
      "\n",
      "   (b) P. Savicky, E. Kotrc.\n",
      "       Experimental Study of Leaf Confidences for Random Forest.\n",
      "       Proceedings of COMPSTAT 2004, In: Computational Statistics.\n",
      "       (Ed.: Antoch J.) - Heidelberg, Physica Verlag 2004, pp. 1767-1774.\n",
      "\n",
      "   (c) J. Dvorak, P. Savicky.\n",
      "       Softening Splits in Decision Trees Using Simulated Annealing.\n",
      "       Proceedings of ICANNGA 2007, Warsaw, (Ed.: Beliczynski et. al),\n",
      "       Part I, LNCS 4431, pp. 721-729.\n",
      "\n",
      "4. Relevant Information:\n",
      "\n",
      "   The data are MC generated (see below) to simulate registration of high energy\n",
      "   gamma particles in a ground-based atmospheric Cherenkov gamma telescope using the\n",
      "   imaging technique. Cherenkov gamma telescope observes high energy gamma rays,\n",
      "   taking advantage of the radiation emitted by charged particles produced\n",
      "   inside the electromagnetic showers initiated by the gammas, and developing in the\n",
      "   atmosphere. This Cherenkov radiation (of visible to UV wavelengths) leaks\n",
      "   through the atmosphere and gets recorded in the detector, allowing reconstruction\n",
      "   of the shower parameters. The available information consists of pulses left by\n",
      "   the incoming Cherenkov photons on the photomultiplier tubes, arranged in a\n",
      "   plane, the camera. Depending on the energy of the primary gamma, a total of\n",
      "   few hundreds to some 10000 Cherenkov photons get collected, in patterns\n",
      "   (called the shower image), allowing to discriminate statistically those\n",
      "   caused by primary gammas (signal) from the images of hadronic showers\n",
      "   initiated by cosmic rays in the upper atmosphere (background).\n",
      "\n",
      "   Typically, the image of a shower after some pre-processing is an elongated\n",
      "   cluster. Its long axis is oriented towards the camera center if the shower axis\n",
      "   is parallel to the telescope's optical axis, i.e. if the telescope axis is\n",
      "   directed towards a point source. A principal component analysis is performed\n",
      "   in the camera plane, which results in a correlation axis and defines an ellipse.\n",
      "   If the depositions were distributed as a bivariate Gaussian, this would be\n",
      "   an equidensity ellipse. The characteristic parameters of this ellipse\n",
      "   (often called Hillas parameters) are among the image parameters that can be\n",
      "   used for discrimination. The energy depositions are typically asymmetric\n",
      "   along the major axis, and this asymmetry can also be used in discrimination.\n",
      "   There are, in addition, further discriminating characteristics, like the\n",
      "   extent of the cluster in the image plane, or the total sum of depositions.\n",
      "\n",
      "   The data set was generated by a Monte Carlo program, Corsika, described in \n",
      "      D. Heck et al., CORSIKA, A Monte Carlo code to simulate extensive air showers,\n",
      "      Forschungszentrum Karlsruhe FZKA 6019 (1998).\n",
      "   The program was run with parameters allowing to observe events with energies down\n",
      "   to below 50 GeV.\n",
      "\n",
      "5. Number of Instances: 19020\n",
      "\n",
      "6. Number of Attributes: 11 (including the class)\n",
      "\n",
      "7. Attribute information:\n",
      "\n",
      "    1.  fLength:  continuous  # major axis of ellipse [mm]\n",
      "    2.  fWidth:   continuous  # minor axis of ellipse [mm] \n",
      "    3.  fSize:    continuous  # 10-log of sum of content of all pixels [in #phot]\n",
      "    4.  fConc:    continuous  # ratio of sum of two highest pixels over fSize  [ratio]\n",
      "    5.  fConc1:   continuous  # ratio of highest pixel over fSize  [ratio]\n",
      "    6.  fAsym:    continuous  # distance from highest pixel to center, projected onto major axis [mm]\n",
      "    7.  fM3Long:  continuous  # 3rd root of third moment along major axis  [mm] \n",
      "    8.  fM3Trans: continuous  # 3rd root of third moment along minor axis  [mm]\n",
      "    9.  fAlpha:   continuous  # angle of major axis with vector to origin [deg]\n",
      "   10.  fDist:    continuous  # distance from origin to center of ellipse [mm]\n",
      "   11.  class:    g,h         # gamma (signal), hadron (background)\n",
      "\n",
      "8. Missing Attribute Values: None\n",
      "\n",
      "9. Class Distribution:\n",
      "\n",
      "   g = gamma (signal):     12332\n",
      "   h = hadron (background): 6688\n",
      "\n",
      "   For technical reasons, the number of h events is underestimated.\n",
      "   In the real data, the h class represents the majority of the events.\n",
      "\n",
      "   The simple classification accuracy is not meaningful for this data, since\n",
      "   classifying a background event as signal is worse than classifying a signal\n",
      "   event as background. For comparison of different classifiers an ROC curve\n",
      "   has to be used. The relevant points on this curve are those, where the\n",
      "   probability of accepting a background event as signal is below one of the\n",
      "   following thresholds: 0.01, 0.02, 0.05, 0.1, 0.2 depending on the required\n",
      "   quality of the sample of the accepted events for different experiments.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat ./magic04.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:45.056867Z",
     "start_time": "2020-07-31T04:54:45.052905Z"
    }
   },
   "outputs": [],
   "source": [
    "columnNames = ['fLength', 'fWidth', 'fSize', 'fConc', 'fConc1', 'fAsym', 'fM3Long', 'fM3Trans', 'fAlpha', 'fDist', 'classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:45.940199Z",
     "start_time": "2020-07-31T04:54:45.906282Z"
    }
   },
   "outputs": [],
   "source": [
    "energy = pd.read_csv(\"magic04.data\", sep=\",\", names=columnNames, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:46.636056Z",
     "start_time": "2020-07-31T04:54:46.579177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fLength</th>\n",
       "      <th>fWidth</th>\n",
       "      <th>fSize</th>\n",
       "      <th>fConc</th>\n",
       "      <th>fConc1</th>\n",
       "      <th>fAsym</th>\n",
       "      <th>fM3Long</th>\n",
       "      <th>fM3Trans</th>\n",
       "      <th>fAlpha</th>\n",
       "      <th>fDist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "      <td>19020.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>53.250154</td>\n",
       "      <td>22.180966</td>\n",
       "      <td>2.825017</td>\n",
       "      <td>0.380327</td>\n",
       "      <td>0.214657</td>\n",
       "      <td>-4.331745</td>\n",
       "      <td>10.545545</td>\n",
       "      <td>0.249726</td>\n",
       "      <td>27.645707</td>\n",
       "      <td>193.818026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>42.364855</td>\n",
       "      <td>18.346056</td>\n",
       "      <td>0.472599</td>\n",
       "      <td>0.182813</td>\n",
       "      <td>0.110511</td>\n",
       "      <td>59.206062</td>\n",
       "      <td>51.000118</td>\n",
       "      <td>20.827439</td>\n",
       "      <td>26.103621</td>\n",
       "      <td>74.731787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.283500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.941300</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.000300</td>\n",
       "      <td>-457.916100</td>\n",
       "      <td>-331.780000</td>\n",
       "      <td>-205.894700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>24.336000</td>\n",
       "      <td>11.863800</td>\n",
       "      <td>2.477100</td>\n",
       "      <td>0.235800</td>\n",
       "      <td>0.128475</td>\n",
       "      <td>-20.586550</td>\n",
       "      <td>-12.842775</td>\n",
       "      <td>-10.849375</td>\n",
       "      <td>5.547925</td>\n",
       "      <td>142.492250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>37.147700</td>\n",
       "      <td>17.139900</td>\n",
       "      <td>2.739600</td>\n",
       "      <td>0.354150</td>\n",
       "      <td>0.196500</td>\n",
       "      <td>4.013050</td>\n",
       "      <td>15.314100</td>\n",
       "      <td>0.666200</td>\n",
       "      <td>17.679500</td>\n",
       "      <td>191.851450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>70.122175</td>\n",
       "      <td>24.739475</td>\n",
       "      <td>3.101600</td>\n",
       "      <td>0.503700</td>\n",
       "      <td>0.285225</td>\n",
       "      <td>24.063700</td>\n",
       "      <td>35.837800</td>\n",
       "      <td>10.946425</td>\n",
       "      <td>45.883550</td>\n",
       "      <td>240.563825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>334.177000</td>\n",
       "      <td>256.382000</td>\n",
       "      <td>5.323300</td>\n",
       "      <td>0.893000</td>\n",
       "      <td>0.675200</td>\n",
       "      <td>575.240700</td>\n",
       "      <td>238.321000</td>\n",
       "      <td>179.851000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>495.561000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            fLength        fWidth         fSize         fConc        fConc1  \\\n",
       "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000   \n",
       "mean      53.250154     22.180966      2.825017      0.380327      0.214657   \n",
       "std       42.364855     18.346056      0.472599      0.182813      0.110511   \n",
       "min        4.283500      0.000000      1.941300      0.013100      0.000300   \n",
       "25%       24.336000     11.863800      2.477100      0.235800      0.128475   \n",
       "50%       37.147700     17.139900      2.739600      0.354150      0.196500   \n",
       "75%       70.122175     24.739475      3.101600      0.503700      0.285225   \n",
       "max      334.177000    256.382000      5.323300      0.893000      0.675200   \n",
       "\n",
       "              fAsym       fM3Long      fM3Trans        fAlpha         fDist  \n",
       "count  19020.000000  19020.000000  19020.000000  19020.000000  19020.000000  \n",
       "mean      -4.331745     10.545545      0.249726     27.645707    193.818026  \n",
       "std       59.206062     51.000118     20.827439     26.103621     74.731787  \n",
       "min     -457.916100   -331.780000   -205.894700      0.000000      1.282600  \n",
       "25%      -20.586550    -12.842775    -10.849375      5.547925    142.492250  \n",
       "50%        4.013050     15.314100      0.666200     17.679500    191.851450  \n",
       "75%       24.063700     35.837800     10.946425     45.883550    240.563825  \n",
       "max      575.240700    238.321000    179.851000     90.000000    495.561000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "energy.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:49.220577Z",
     "start_time": "2020-07-31T04:54:49.215592Z"
    }
   },
   "outputs": [],
   "source": [
    "def check_purity(dataset):\n",
    "    column = dataset.iloc[:,-1]\n",
    "    unique_values = np.unique(column)\n",
    "    if (len(unique_values) == 1):\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for checking if data in a dataset is pure (only contains class variables 'g' or 'h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:50.773052Z",
     "start_time": "2020-07-31T04:54:50.767068Z"
    }
   },
   "outputs": [],
   "source": [
    "def classify_data(dataset):\n",
    "    column = dataset.iloc[:,-1]\n",
    "    classes, counts = np.unique(column, return_counts=True)\n",
    "    index = counts.argmax()\n",
    "    classification = classes[index]\n",
    "    \n",
    "    return classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "classifying all of the dataset['classes'] as either 'g' or 'h' depending on frequency of each variable in the datasetda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:51.948596Z",
     "start_time": "2020-07-31T04:54:51.941643Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_potential_splits(dataset):\n",
    "    potential_splits = {}\n",
    "    columns = dataset.shape[1]\n",
    "    for column_index in range(columns - 1):\n",
    "        potential_splits[column_index] = []\n",
    "        values = dataset.iloc[:, column_index]\n",
    "        unique_values = np.unique(values)                #get unique values as potential splits\n",
    "        \n",
    "        index = len(unique_values)-1\n",
    "        unique_values = np.delete(unique_values, index)  #delete last element so split_data() method will not give empty\n",
    "                                                         #dataset for data_above (data_above > unique_value where\n",
    "                                                         #unique_value is column.max() will result in data_above being empty)\n",
    "        potential_splits[column_index] = unique_values\n",
    "        \n",
    "    return potential_splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "every unique value in each of the dataset's columns are potential splits.\n",
    "\n",
    "e.g. fLength's minimum value can be a potential splitting point where data_below will be the rows where dataset['fLength'] <= fLength's minimum value and the data_above will be dataset['fLength'] > fLength's minimum value\n",
    "\n",
    "we hold the potential splits in a dictionary of lists for further processing later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:53.631158Z",
     "start_time": "2020-07-31T04:54:53.626171Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_data(dataset, split_column, split_value):\n",
    "    split_column_values = dataset.iloc[:, split_column]\n",
    "    \n",
    "    data_below = dataset[split_column_values <= split_value]\n",
    "    data_above = dataset[split_column_values > split_value]\n",
    "    \n",
    "    return data_below, data_above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "used in conjunction with the potential splits later to determine which split will result in the best metric gain/loss depending on the tree splitting metric (information gain, gain ratio, variance, gini index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:55.894259Z",
     "start_time": "2020-07-31T04:54:55.890246Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_entropy(dataset):\n",
    "    class_column = dataset.iloc[:,-1]\n",
    "    probabilities = class_column.value_counts(normalize=True)\n",
    "    entropy = sum(probabilities * -np.log2(probabilities))\n",
    "    return entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:56.891782Z",
     "start_time": "2020-07-31T04:54:56.885799Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_gini_index(dataset):\n",
    "    class_column = dataset.iloc[:,-1]\n",
    "    probabilities = class_column.value_counts(normalize=True)\n",
    "    gini = 1 - sum(probabilities**2)\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:57.437840Z",
     "start_time": "2020-07-31T04:54:57.431856Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_variance(dataset):\n",
    "    class_column = dataset.iloc[:,-1]\n",
    "    probabilities = class_column.value_counts()\n",
    "    unique = np.unique(class_column.values)\n",
    "    total_rows = len(class_column)\n",
    "    \n",
    "    if (len(unique) == 1):\n",
    "        if(unique[0] == 'g' ):\n",
    "            gCount = probabilities[0]\n",
    "            hCount = 0\n",
    "        else:\n",
    "            hCount = probabilities[0]\n",
    "            gCount = 0\n",
    "    elif (unique[0] == 'g'):\n",
    "        gCount = probabilities[0]\n",
    "        hCount = probabilities[1]\n",
    "    \n",
    "    mean = (gCount)/total_rows\n",
    "    #let g = 1 and h = 0\n",
    "    variance = ((gCount*(1-mean)**2) + (hCount*(0-mean)**2)) / total_rows\n",
    "    return variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:58.208393Z",
     "start_time": "2020-07-31T04:54:58.203408Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weighted_average(metric, data_below, data_above):\n",
    "    total_rows = len(data_below) + len(data_above)\n",
    "    prob_data_below = len(data_below) / total_rows\n",
    "    prob_data_above = len(data_above) / total_rows\n",
    "    \n",
    "    weighted_average = (prob_data_below * metric(data_below)\n",
    "                        +\n",
    "                        prob_data_above * metric(data_above))\n",
    "    \n",
    "    return weighted_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:54:58.715646Z",
     "start_time": "2020-07-31T04:54:58.709663Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_best_split_InfoGain(dataset, potential_splits):\n",
    "    metric = calculate_entropy\n",
    "    largest_InfoGain = 0\n",
    "    \n",
    "    parent_entropy = calculate_entropy(dataset)\n",
    "    for index in potential_splits:\n",
    "        for value in potential_splits[index]:\n",
    "            data_below, data_above = split_data(dataset, index, value)            \n",
    "            current_overall_entropy = calculate_weighted_average(metric, data_below, data_above)\n",
    "            infoGain = parent_entropy - current_overall_entropy\n",
    "            \n",
    "            if (infoGain > largest_InfoGain):\n",
    "                largest_InfoGain = infoGain   #assign new largest info gain for subsequent comparisons\n",
    "                best_split_column = index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using potential_splits and split_data from the previous methods, we split_data at every potential split and calculate entropy to get infoGain. save the largest infoGain value in largest_InfoGain variable. at the end of iterating potential_splits, largest_InfoGain will be the split in data which results in the largest InfoGain. we return the column and value of that split.\n",
    "\n",
    "Similar implementation for the other determine_best_split_metric() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:00.106139Z",
     "start_time": "2020-07-31T04:55:00.100157Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_best_split_GainRatio(dataset, potential_splits):\n",
    "    metric = calculate_entropy\n",
    "    largest_GainRatio = 0\n",
    "    \n",
    "    parent_entropy = calculate_entropy(dataset)\n",
    "    \n",
    "    for index in potential_splits:\n",
    "        for value in potential_splits[index]:\n",
    "            data_below, data_above = split_data(dataset, index, value)            \n",
    "            current_overall_entropy = calculate_weighted_average(metric, data_below, data_above)\n",
    "            infoGain = parent_entropy - current_overall_entropy\n",
    "            gainRatio = infoGain / parent_entropy\n",
    "            \n",
    "            if (gainRatio > largest_GainRatio):\n",
    "                largest_GainRatio = gainRatio\n",
    "                best_split_column = index\n",
    "                best_split_value = value            \n",
    "            \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:02.474168Z",
     "start_time": "2020-07-31T04:55:02.466191Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_best_split_variance(dataset, potential_splits):\n",
    "    metric = calculate_variance\n",
    "    smallest_variance = 999\n",
    "    \n",
    "    parentVariance = calculate_variance(dataset)\n",
    "    for index in potential_splits:\n",
    "        for value in potential_splits[index]:\n",
    "            data_below, data_above = split_data(dataset, index, value)            \n",
    "            current_overall_var = calculate_weighted_average(metric, data_below, data_above)\n",
    "            varReduction = parentVariance - current_overall_var\n",
    "            #smaller variance in data = data becoming less impure\n",
    "            \n",
    "            if (varReduction < smallest_variance):\n",
    "                smallest_variance = varReduction   #assign new smallest variance for subsequent comparisons\n",
    "                best_split_column = index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:03.317601Z",
     "start_time": "2020-07-31T04:55:03.308638Z"
    }
   },
   "outputs": [],
   "source": [
    "def determine_best_split_GiniIndex(dataset, potential_splits):\n",
    "    metric = calculate_gini_index\n",
    "    largest_GiniIndex = 0\n",
    "    \n",
    "    parentGini = calculate_gini_index(dataset)\n",
    "    for index in potential_splits:\n",
    "        for value in potential_splits[index]:\n",
    "            data_below, data_above = split_data(dataset, index, value)            \n",
    "            current_overall_gini = calculate_weighted_average(metric, data_below, data_above)\n",
    "            giniReduction = parentGini - current_overall_gini\n",
    "            #larger giniReduction = larger reduction in gini impurity\n",
    "            \n",
    "            if (giniReduction > largest_GiniIndex):\n",
    "                largest_GiniIndex = giniReduction   #assign new largest info gain for subsequent comparisons\n",
    "                best_split_column = index\n",
    "                best_split_value = value\n",
    "    \n",
    "    return best_split_column, best_split_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:24:40.842379Z",
     "start_time": "2020-07-31T05:24:40.833371Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_tree_InfoGain(dataset, counter=0, max_depth=10): #min_samples=5, max_depth=5):\n",
    "    \n",
    "    if counter == 0:   #initial execution\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataset.columns\n",
    "        data = pd.DataFrame(data=dataset)\n",
    "    else:              #recursive execution\n",
    "        data = dataset\n",
    "    \n",
    "    #base case\n",
    "    if (check_purity(data)) or (counter == max_depth): #(len(data) < min_samples)\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    #recursive portion\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        #auxiliary functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split_InfoGain(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        #grow sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        split_criteria = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {split_criteria: []}\n",
    "        \n",
    "        yes_branch = decision_tree_InfoGain(data_below, counter)#, min_samples, max_depth)\n",
    "        no_branch = decision_tree_InfoGain(data_above, counter)#, min_samples, max_depth)\n",
    "        \n",
    "        if (yes_branch == no_branch):\n",
    "            sub_tree = yes_branch\n",
    "        else:\n",
    "            sub_tree[split_criteria].append(yes_branch)\n",
    "            sub_tree[split_criteria].append(no_branch)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in base case, if data is pure, we can immediately classify it. if not pure yet, we will continue growing the decision tree in the recursive portion.\n",
    "first, get the potential_splits of the data, then determine_best_split_metric.\n",
    "\n",
    "the split_criteria will be a string known as:\n",
    "the feature returned by determine_best_split_metric, feature_name, <= operator, and split_value.\n",
    "we put this in a list inside a dictionary called sub_tree.\n",
    "\n",
    "using the splitted data, we recursively call the decision_tree_metric method for each splitted data, data_below and data_above.\n",
    "the segmented data will then check it's purity, and if not pure, get it's potential splits, determine it's best split, and getting more splitting criterias to grow the tree.\n",
    "\n",
    "once the data_below or data_above is pure, it will be classified by the classify_data() method mentioned previously, resulting in sub_tree = the classified alphabet ('g' or 'h'). If the yes_branch and no_branch result in the same sub_tree, sub_tree will denote the classified alphabet (this is the very end of the tree). If not, then the sub_tree will be appended by the splitting_criteria.\n",
    "\n",
    "the method call will result in a the decision tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:24:43.286622Z",
     "start_time": "2020-07-31T05:24:43.279640Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_tree_GainRatio(dataset, counter=0, max_depth=10): #min_samples=10, max_depth=10):\n",
    "    \n",
    "    if counter == 0:   #initial execution\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataset.columns\n",
    "        data = pd.DataFrame(data=dataset)\n",
    "    else:              #recursive execution\n",
    "        data = dataset\n",
    "    \n",
    "    #base case\n",
    "    if (check_purity(data)) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    #recursive portion\n",
    "    else:        \n",
    "        counter += 1\n",
    "        \n",
    "        #auxiliary functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split_GainRatio(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        #grow sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        split_criteria = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {split_criteria: []}\n",
    "        \n",
    "        yes_branch = decision_tree_GainRatio(data_below, counter)\n",
    "        no_branch = decision_tree_GainRatio(data_above, counter)\n",
    "        \n",
    "        if (yes_branch == no_branch):\n",
    "            sub_tree = yes_branch\n",
    "        else:\n",
    "            sub_tree[split_criteria].append(yes_branch)\n",
    "            sub_tree[split_criteria].append(no_branch)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:10:50.514327Z",
     "start_time": "2020-07-31T05:10:50.505350Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_tree_variance(dataset, counter=0, max_depth=10):\n",
    "    \n",
    "    if counter == 0:   #initial execution\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataset.columns\n",
    "        data = pd.DataFrame(data=dataset)\n",
    "    else:              #recursive execution\n",
    "        data = dataset\n",
    "    \n",
    "    #base case\n",
    "    if (check_purity(data)) or (counter == max_depth):\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    #recursive portion\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        #auxiliary functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split_variance(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        #grow sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        split_criteria = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {split_criteria: []}\n",
    "        \n",
    "        yes_branch = decision_tree_variance(data_below, counter)\n",
    "        no_branch = decision_tree_variance(data_above, counter)\n",
    "        \n",
    "        if (yes_branch == no_branch):\n",
    "            sub_tree = yes_branch\n",
    "        else:\n",
    "            sub_tree[split_criteria].append(yes_branch)\n",
    "            sub_tree[split_criteria].append(no_branch)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:24:52.128935Z",
     "start_time": "2020-07-31T05:24:52.120954Z"
    }
   },
   "outputs": [],
   "source": [
    "def decision_tree_GiniIndex(dataset, counter=0, max_depth=10):#, min_samples=10, max_depth=10):\n",
    "    \n",
    "    if counter == 0:   #initial execution\n",
    "        global COLUMN_HEADERS\n",
    "        COLUMN_HEADERS = dataset.columns\n",
    "        data = pd.DataFrame(data=dataset)\n",
    "    else:              #recursive execution\n",
    "        data = dataset\n",
    "    \n",
    "    #base case\n",
    "    if (check_purity(data)) or (counter == max_depth):  #or (len(data) < min_samples)\n",
    "        classification = classify_data(data)\n",
    "        return classification\n",
    "    \n",
    "    #recursive portion\n",
    "    else:\n",
    "        counter += 1\n",
    "        \n",
    "        #auxiliary functions\n",
    "        potential_splits = get_potential_splits(data)\n",
    "        split_column, split_value = determine_best_split_GiniIndex(data, potential_splits)\n",
    "        data_below, data_above = split_data(data, split_column, split_value)\n",
    "        \n",
    "        #grow sub-tree\n",
    "        feature_name = COLUMN_HEADERS[split_column]\n",
    "        split_criteria = \"{} <= {}\".format(feature_name, split_value)\n",
    "        sub_tree = {split_criteria: []}\n",
    "        \n",
    "        yes_branch = decision_tree_GiniIndex(data_below, counter)#, min_samples, max_depth)\n",
    "        no_branch = decision_tree_GiniIndex(data_above, counter)#, min_samples, max_depth)\n",
    "        \n",
    "        if (yes_branch == no_branch):\n",
    "            sub_tree = yes_branch\n",
    "        else:\n",
    "            sub_tree[split_criteria].append(yes_branch)\n",
    "            sub_tree[split_criteria].append(no_branch)\n",
    "        \n",
    "        return sub_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:09.856623Z",
     "start_time": "2020-07-31T04:55:09.846655Z"
    }
   },
   "outputs": [],
   "source": [
    "def classifier(example, tree):\n",
    "    split_criteria = list(tree.keys())[0]\n",
    "    feature_name, _, value = split_criteria.split()\n",
    "    \n",
    "    if example[feature_name] <= float(value):\n",
    "        answer = tree[split_criteria][0]\n",
    "    else:\n",
    "        answer = tree[split_criteria][1]\n",
    "        \n",
    "    if not isinstance(answer, dict):\n",
    "        return answer\n",
    "    else:\n",
    "        residual_tree = answer\n",
    "        return classifier(example, residual_tree)  #traverse tree until answer is a leaf node instead of split_criteria"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the decision tree's dictionary key is the split_criteria. we use list to get the split_criteria as a variable to use as an index to get the nested lists the dictionary holds.\n",
    "\n",
    "the nested lists we get will be the true and false portion of the decision tree's split_criteria.\n",
    "\n",
    "recursively, we apply the same logic on the true or false portion of the initial split criteria (which depends on the example's data we used for the method). the recursion happens until we reach the end of the tree.\n",
    "\n",
    "the answer we get is the decision_tree's classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:11.160144Z",
     "start_time": "2020-07-31T04:55:11.155156Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_classification(dataset, tree):\n",
    "    \n",
    "    predictions = dataset.apply(classifier, axis=1, args=(tree,))\n",
    "    predictions = predictions.to_numpy()       \n",
    "    \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get a np.array of predicted 'g' or 'h' values based on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:13.076387Z",
     "start_time": "2020-07-31T04:55:13.072370Z"
    }
   },
   "outputs": [],
   "source": [
    "def append_classifier(dataset, tree, columnName):\n",
    "    \n",
    "    dataset[columnName] = get_classification(dataset, tree)\n",
    "        \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "append the np.array to the test data to compare the class columns with our decision_tree's predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:14.105386Z",
     "start_time": "2020-07-31T04:55:14.096898Z"
    }
   },
   "outputs": [],
   "source": [
    "def ensemble_classifier(testset, tree1, tree2, tree3):\n",
    "    \n",
    "    classify_IG = get_classification(testset, tree1)    \n",
    "    classify_GR = get_classification(testset, tree2)\n",
    "    classify_var = get_classification(testset, tree3)\n",
    "    classify_ensemble = []\n",
    "\n",
    "    for i in range(len(classify_IG)):\n",
    "        selection = []\n",
    "        selection.append(classify_IG[i])\n",
    "        selection.append(classify_GR[i])\n",
    "        selection.append(classify_var[i])\n",
    "        mode = Counter(selection)\n",
    "        classify_ensemble.append(mode.most_common(1)[0][0])\n",
    "\n",
    "    return classify_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using the 3 decision tree classifiers, InfoGainTree, GainRatioTree, and varianceTree, use the above voting function to get the highest frequency of 'g' or 'h' to determine the ensemble's prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:44.700443Z",
     "start_time": "2020-07-31T04:55:44.663502Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "xTrain = []\n",
    "xTest = []\n",
    "yTrain = []\n",
    "yTest = []\n",
    "\n",
    "X = energy.iloc[:,:10]\n",
    "y = energy.iloc[:,10]\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "skf.get_n_splits(X,y)\n",
    "for train_index, test_index in skf.split(X,y):\n",
    "    xTrain.append(X.iloc[train_index])\n",
    "    xTest.append(X.iloc[test_index])\n",
    "    yTrain.append(y.iloc[train_index])\n",
    "    yTest.append(y.iloc[test_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:47.091132Z",
     "start_time": "2020-07-31T04:55:47.066198Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnkr9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\dnkr9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "cross_train = []\n",
    "cross_test = []\n",
    "for i in range(len(xTrain)):\n",
    "    xTrain[i]['classes'] = yTrain[i]\n",
    "    xTest[i]['classes'] = yTest[i]\n",
    "    cross_train.append(xTrain[i])\n",
    "    cross_test.append(xTest[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:53.281699Z",
     "start_time": "2020-07-31T04:55:53.196961Z"
    }
   },
   "outputs": [],
   "source": [
    "#sample from test portion to reduce decision_tree training time\n",
    "total = len(cross_train[0])\n",
    "g_normalize,h_normalize = cross_train[0].classes.value_counts(normalize=True)\n",
    "sample_cross_train = []\n",
    "for i in range(len(cross_train)):\n",
    "    temp = pd.concat([cross_train[i][cross_train[i].classes=='g'].sample(int((1/9*total)*g_normalize)), energy[energy.classes=='h'].sample(int((1/9*total)*h_normalize))])\n",
    "    sample_cross_train.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:55.254624Z",
     "start_time": "2020-07-31T04:55:55.247643Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    1233\n",
       "h     668\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_cross_train[0].classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T04:55:56.143812Z",
     "start_time": "2020-07-31T04:55:56.135834Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "g    1234\n",
       "h     668\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_test[0].classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:08:52.377668Z",
     "start_time": "2020-07-31T04:56:29.445137Z"
    }
   },
   "outputs": [],
   "source": [
    "InfoGainTree = decision_tree_InfoGain(sample_cross_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:36:50.314855Z",
     "start_time": "2020-07-31T05:25:35.339331Z"
    }
   },
   "outputs": [],
   "source": [
    "InfoGainTree2 = decision_tree_InfoGain(sample_cross_train[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T07:02:23.438054Z",
     "start_time": "2020-07-31T05:42:41.298264Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(2,10):\n",
    "    InfoGainTree = decision_tree_InfoGain(sample_cross_train[i])\n",
    "    InfoGain_Trees.append(InfoGainTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T07:10:45.843353Z",
     "start_time": "2020-07-31T07:10:45.838367Z"
    }
   },
   "outputs": [],
   "source": [
    "InfoGain_Trees = []\n",
    "GainRatio_Trees = []\n",
    "GiniIndex_Trees = []\n",
    "variance_Trees = []\n",
    "ensemble_List = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to lack of time to train my decision tree models, I have not only sampled the training portion of the KFold split, but i am also only using 5 folds instead of 10 to evaluate the signicance in mean errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T08:04:41.460345Z",
     "start_time": "2020-07-31T07:10:50.622443Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    GainRatioTree = decision_tree_GainRatio(sample_cross_train[i])\n",
    "    GainRatio_Trees.append(GainRatioTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T09:00:57.430201Z",
     "start_time": "2020-07-31T08:10:10.861275Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    GiniIndexTree = decision_tree_GiniIndex(sample_cross_train[i])\n",
    "    GiniIndex_Trees.append(GiniIndexTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T09:44:05.244304Z",
     "start_time": "2020-07-31T09:01:21.666395Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    varTree = decision_tree_variance(sample_cross_train[i])\n",
    "    variance_Trees.append(varTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T05:22:02.573877Z",
     "start_time": "2020-07-31T05:11:29.677095Z"
    }
   },
   "outputs": [],
   "source": [
    "varTree = decision_tree_variance(sample_cross_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T09:55:22.780377Z",
     "start_time": "2020-07-31T09:55:20.272841Z"
    }
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "    ensemble = ensemble_classifier(cross_test[i], InfoGain_Trees[i], GainRatio_Trees[i], variance_Trees[i])\n",
    "    ensemble_List.append(ensemble)\n",
    "    #need to manually append ensemble_predictions[i] to the cross_test[i] dataset so that can do pd.crosstab for error calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T09:58:01.733875Z",
     "start_time": "2020-07-31T09:58:01.723902Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnkr9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    cross_test[i]['Ensemble'] = ensemble_List[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T09:57:46.027007Z",
     "start_time": "2020-07-31T09:57:45.069172Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dnkr9\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,5):\n",
    "    append_classifier(cross_test[i], GiniIndex_Trees[i], 'GiniIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:00:58.785705Z",
     "start_time": "2020-07-31T10:00:58.781318Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_error = []\n",
    "giniIndex_error = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GiniIndex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:01:01.979557Z",
     "start_time": "2020-07-31T10:01:01.939663Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GiniIndex</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1058</td>\n",
       "      <td>176</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>192</td>\n",
       "      <td>476</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1250</td>\n",
       "      <td>652</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GiniIndex     g    h   All\n",
       "classes                   \n",
       "g          1058  176  1234\n",
       "h           192  476   668\n",
       "All        1250  652  1902"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[0]['classes'], cross_test[0]['GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:01:03.735151Z",
     "start_time": "2020-07-31T10:01:03.728166Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1058 + 476) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "giniIndex_error.append(error) #0.1934"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:02:36.077090Z",
     "start_time": "2020-07-31T10:02:36.034171Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GiniIndex</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1111</td>\n",
       "      <td>123</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>231</td>\n",
       "      <td>437</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1342</td>\n",
       "      <td>560</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GiniIndex     g    h   All\n",
       "classes                   \n",
       "g          1111  123  1234\n",
       "h           231  437   668\n",
       "All        1342  560  1902"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[1]['classes'], cross_test[1]['GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:02:37.922678Z",
     "start_time": "2020-07-31T10:02:37.918655Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1111 + 437) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "giniIndex_error.append(error) #0.1861"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:03:50.036629Z",
     "start_time": "2020-07-31T10:03:49.994742Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GiniIndex</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1087</td>\n",
       "      <td>146</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>195</td>\n",
       "      <td>474</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1282</td>\n",
       "      <td>620</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GiniIndex     g    h   All\n",
       "classes                   \n",
       "g          1087  146  1233\n",
       "h           195  474   669\n",
       "All        1282  620  1902"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[2]['classes'], cross_test[2]['GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:04:18.214186Z",
     "start_time": "2020-07-31T10:04:18.210226Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1087 + 474) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "giniIndex_error.append(error) #0.1793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:04:39.072107Z",
     "start_time": "2020-07-31T10:04:39.031217Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GiniIndex</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1094</td>\n",
       "      <td>139</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>196</td>\n",
       "      <td>473</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1290</td>\n",
       "      <td>612</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GiniIndex     g    h   All\n",
       "classes                   \n",
       "g          1094  139  1233\n",
       "h           196  473   669\n",
       "All        1290  612  1902"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[3]['classes'], cross_test[3]['GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:05:06.017332Z",
     "start_time": "2020-07-31T10:05:06.013343Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1094 + 473) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "giniIndex_error.append(error) #0.1761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:05:22.933470Z",
     "start_time": "2020-07-31T10:05:22.895546Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>GiniIndex</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1067</td>\n",
       "      <td>166</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>205</td>\n",
       "      <td>464</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1272</td>\n",
       "      <td>630</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "GiniIndex     g    h   All\n",
       "classes                   \n",
       "g          1067  166  1233\n",
       "h           205  464   669\n",
       "All        1272  630  1902"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[4]['classes'], cross_test[4]['GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:05:53.452968Z",
     "start_time": "2020-07-31T10:05:53.446984Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1067 + 464) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "giniIndex_error.append(error) #0.1951"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ensemble:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:06:21.438669Z",
     "start_time": "2020-07-31T10:06:21.396750Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ensemble</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1096</td>\n",
       "      <td>138</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>203</td>\n",
       "      <td>465</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1299</td>\n",
       "      <td>603</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ensemble     g    h   All\n",
       "classes                  \n",
       "g         1096  138  1234\n",
       "h          203  465   668\n",
       "All       1299  603  1902"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[0]['classes'], cross_test[0]['Ensemble'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:06:58.242394Z",
     "start_time": "2020-07-31T10:06:58.238403Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1096 + 465) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "ensemble_error.append(error) #0.1793"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:07:24.335686Z",
     "start_time": "2020-07-31T10:07:24.289810Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ensemble</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1043</td>\n",
       "      <td>191</td>\n",
       "      <td>1234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>194</td>\n",
       "      <td>474</td>\n",
       "      <td>668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1237</td>\n",
       "      <td>665</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ensemble     g    h   All\n",
       "classes                  \n",
       "g         1043  191  1234\n",
       "h          194  474   668\n",
       "All       1237  665  1902"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[1]['classes'], cross_test[1]['Ensemble'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:07:51.644977Z",
     "start_time": "2020-07-31T10:07:51.639990Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1043 + 474) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "ensemble_error.append(error) #0.2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:08:02.459885Z",
     "start_time": "2020-07-31T10:08:02.412051Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ensemble</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1074</td>\n",
       "      <td>159</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>191</td>\n",
       "      <td>478</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1265</td>\n",
       "      <td>637</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ensemble     g    h   All\n",
       "classes                  \n",
       "g         1074  159  1233\n",
       "h          191  478   669\n",
       "All       1265  637  1902"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[2]['classes'], cross_test[2]['Ensemble'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:08:27.863753Z",
     "start_time": "2020-07-31T10:08:27.857766Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1074 + 478) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "ensemble_error.append(error) #0.1840"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:08:45.181260Z",
     "start_time": "2020-07-31T10:08:45.138417Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ensemble</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1080</td>\n",
       "      <td>153</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>185</td>\n",
       "      <td>484</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1265</td>\n",
       "      <td>637</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ensemble     g    h   All\n",
       "classes                  \n",
       "g         1080  153  1233\n",
       "h          185  484   669\n",
       "All       1265  637  1902"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[3]['classes'], cross_test[3]['Ensemble'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:09:08.119270Z",
     "start_time": "2020-07-31T10:09:08.115287Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1080 + 484) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "ensemble_error.append(error) #0.1777"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:09:19.284097Z",
     "start_time": "2020-07-31T10:09:19.241214Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Ensemble</th>\n",
       "      <th>g</th>\n",
       "      <th>h</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>classes</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>g</th>\n",
       "      <td>1042</td>\n",
       "      <td>191</td>\n",
       "      <td>1233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>h</th>\n",
       "      <td>171</td>\n",
       "      <td>498</td>\n",
       "      <td>669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>1213</td>\n",
       "      <td>689</td>\n",
       "      <td>1902</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Ensemble     g    h   All\n",
       "classes                  \n",
       "g         1042  191  1233\n",
       "h          171  498   669\n",
       "All       1213  689  1902"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.crosstab(cross_test[4]['classes'], cross_test[4]['Ensemble'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:09:39.742497Z",
     "start_time": "2020-07-31T10:09:39.736515Z"
    }
   },
   "outputs": [],
   "source": [
    "accuracy = (1042 + 498) / 1902\n",
    "accuracy\n",
    "error = 1 - accuracy\n",
    "error\n",
    "ensemble_error.append(error) #0.1903"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Determine the statistical significance of the error rate difference between ensemble model(M1) and gini-index model(M2).\n",
    "\n",
    "H0: M1 and M2 are significantly different.\n",
    "H1: M1 and M2 are not significantly different."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:09:55.120153Z",
     "start_time": "2020-07-31T10:09:55.115166Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.17928496319663512,\n",
       " 0.20241850683491058,\n",
       " 0.18401682439537326,\n",
       " 0.17770767613038907,\n",
       " 0.19032597266035756]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble_error\n",
    "giniIndex_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:10:43.711639Z",
     "start_time": "2020-07-31T10:10:43.706650Z"
    }
   },
   "outputs": [],
   "source": [
    "ensemble_mean_error = sum(ensemble_error)/len(ensemble_error)\n",
    "giniIndex_mean_error = sum(giniIndex_error)/len(giniIndex_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:23:10.189793Z",
     "start_time": "2020-07-31T10:23:10.183705Z"
    }
   },
   "outputs": [],
   "source": [
    "diffSquaredSum = 0\n",
    "for i in range(len(ensemble_error)):\n",
    "    diff = ensemble_error[i] - ensemble_mean_error\n",
    "    diffSquared = diff**2\n",
    "    diffSquaredSum += diffSquared\n",
    "ensemble_variance = diffSquaredSum/len(ensemble_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:23:50.076091Z",
     "start_time": "2020-07-31T10:23:50.071139Z"
    }
   },
   "outputs": [],
   "source": [
    "diffSquaredSum = 0\n",
    "for i in range(len(giniIndex_error)):\n",
    "    diff = giniIndex_error[i] - giniIndex_mean_error\n",
    "    diffSquared = diff**2\n",
    "    diffSquaredSum += diffSquared\n",
    "giniIndex_variance = diffSquaredSum/len(giniIndex_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:26:38.516871Z",
     "start_time": "2020-07-31T10:26:38.512849Z"
    }
   },
   "outputs": [],
   "source": [
    "#var(M1 - M2)\n",
    "varM1M2 = np.sqrt(((giniIndex_variance / 5) + (ensemble_variance / 5)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:27:04.968222Z",
     "start_time": "2020-07-31T10:27:04.964246Z"
    }
   },
   "outputs": [],
   "source": [
    "#t-test\n",
    "t = (giniIndex_mean_error - ensemble_mean_error) / np.sqrt((varM1M2/5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:27:17.738839Z",
     "start_time": "2020-07-31T10:27:17.732886Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.022759379403082952"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "at 5% significance level, df = 4, critical value = +/-2.776\n",
    "since t* = -0.022 > critical value(-2.776), t* does not lie in the rejection region.\n",
    "Hence, H0 is not rejected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Post-Pruning Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:40:22.003495Z",
     "start_time": "2020-07-31T10:40:21.996514Z"
    }
   },
   "outputs": [],
   "source": [
    "def filter_df(df, split_criteria):\n",
    "    feature, _, value = split_criteria.split()\n",
    "    left = df[df[feature] <= float(value)]\n",
    "    right = df[df[feature] > float(value)]\n",
    "    print(split_criteria)\n",
    "    print(left.shape)\n",
    "    print(right.shape)\n",
    "    return left, right"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "filter dataset by split_criteria for use in recursive call later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:40:23.359698Z",
     "start_time": "2020-07-31T10:40:23.349768Z"
    }
   },
   "outputs": [],
   "source": [
    "def pruning_results(tree, trainset, pruneset):\n",
    "    \n",
    "    print(\"pruneset: \")\n",
    "    print(pruneset.classes.value_counts())\n",
    "    \n",
    "    if (pruneset.shape[0] == 0):\n",
    "        leaf = trainset.classes.value_counts().index[0]\n",
    "        return leaf\n",
    "    else:\n",
    "        \n",
    "        print(\"bef value_counts()\")\n",
    "        print(trainset.classes.value_counts())\n",
    "        print(\"aft value_counts()\")\n",
    "        leaf = trainset.classes.value_counts().index[0] #[0] is the higher count, which means classify_data() will classify all values as index[0]\n",
    "        errors_leaf = sum(pruneset.classes != leaf)     #pruneset.classes != classified value = error\n",
    "        print(\"leaf: {}\".format(leaf))\n",
    "        print(\"errors_leaf: {}\".format(errors_leaf))\n",
    "        errors_decision_node = sum(pruneset.classes != get_classification(pruneset, tree))\n",
    "        print(\"errors_decision_node: {}\".format(errors_decision_node))\n",
    "        \n",
    "                                                #run prediction on pruneset and compare to get number of decision_node errors\n",
    "    \n",
    "        if (errors_leaf <= errors_decision_node):   #return one with less errorss for better overall accuracy\n",
    "            return leaf\n",
    "        else:\n",
    "            return tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:40:24.286527Z",
     "start_time": "2020-07-31T10:40:24.279515Z"
    }
   },
   "outputs": [],
   "source": [
    "def post_pruning(tree, trainset, pruneset):\n",
    "    split_criteria = list(tree.keys())[0]\n",
    "    left, right = tree[split_criteria]\n",
    "    \n",
    "    #base case\n",
    "    if not isinstance(left, dict) and not isinstance(right, dict):\n",
    "        print(\"left dict?: {}\".format(left))\n",
    "        print(\"right dict?: {}\".format(right))\n",
    "        return pruning_results(tree, trainset, pruneset)\n",
    "    \n",
    "    #recursive portion - when left and right are still decision nodes\n",
    "    else:\n",
    "        print(\"left filter:\")\n",
    "        train_left, train_right = filter_df(trainset, split_criteria) #filter train by split_criteria\n",
    "        print(\"right filter:\")\n",
    "        prune_left, prune_right = filter_df(pruneset, split_criteria) #filter prune by split_criteria\n",
    "        \n",
    "        if isinstance(left, dict):\n",
    "            left = post_pruning(left, train_left, prune_left)     #keep calling post_pruning until we reach leaf nodes\n",
    "        \n",
    "        if isinstance(right, dict):\n",
    "            right = post_pruning(right, train_right, prune_right) #keep calling post_pruning until we reach leaf nodes\n",
    "        \n",
    "        tree = {split_criteria: [left, right]}             #once we get back, return the pruning results into the tree\n",
    "        \n",
    "        return pruning_results(tree, trainset, pruneset)   #test if leaf or decision nodes have more errors and return accordingly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using recursion to traverse the tree, we decide if we should prune the last split_criteria from the tree by looking at the split_criteria's left and right values.\n",
    "\n",
    "base case:\n",
    "if the left and right are not decision nodes(split_criteria), meaning they are leaf nodes('g', 'h') (the result of classify_data()), we look at our train dataset's class distribution and take the higher frequency (because classify_data() classifies all the data as the higher frequency value). this is the leaf node's value. (either 'g' or 'h')\n",
    "\n",
    "we sum the no. of rows of data where prune dataset's class value is != to the leaf node's value. this is the number of errors of the leaf node's classification.\n",
    "\n",
    "next, we sum the no. of rows of data where prune dataset's class values != to the decision node's prediction of the prune dataset's class values. we sum the count and this is the number of errors of the decision node.\n",
    "\n",
    "we compare the no. of errors in the leaf's classification and the no. of errors of the decision node. if there are more errors in the leaf's classification, then we return the decision node. else we reutrn the leaf node.\n",
    "\n",
    "\n",
    "recursion part:\n",
    "call post_pruning until we reach leaf nodes for base case scenario to happen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:40:26.357873Z",
     "start_time": "2020-07-31T10:40:26.348896Z"
    }
   },
   "outputs": [],
   "source": [
    "g_normalize,h_normalize = energy['classes'].value_counts(normalize=True)\n",
    "total = energy.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:40:31.004347Z",
     "start_time": "2020-07-31T10:40:30.970437Z"
    }
   },
   "outputs": [],
   "source": [
    "train = pd.concat([energy[energy.classes=='g'].sample(int((1/3*total)*g_normalize)), energy[energy.classes=='h'].sample(int((1/3*total)*h_normalize))])\n",
    "subset = energy.loc[~energy.index.isin(train.index)]\n",
    "total = subset.shape[0]\n",
    "prune = pd.concat([subset[subset.classes=='g'].sample(int((1/2*total)*g_normalize)), subset[subset.classes=='h'].sample(int((1/2*total)*h_normalize))])\n",
    "test = subset.loc[~subset.index.isin(prune.index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "stratified sampling where:\n",
    "train is 1/3 of the base dataset,\n",
    "\n",
    "subset is 2/3 of the base subset where train's row indexes are not in it. subset is only used to get prune and test datasets as follows:\n",
    "\n",
    "prune is 1/2 of the subset (1/2subset * 2/3base = 1/3base)\n",
    "test is the other 1/2 of subset where prune's row indexes are not in it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for this portion, i restarted my kernel by mistake and did not have enough time to re-run the decision tree. the code has been tested and is working. running it should work fine albeit a 10minute training time for the GiniIndexTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:44:29.334300Z",
     "start_time": "2020-07-31T10:43:29.396448Z"
    }
   },
   "outputs": [],
   "source": [
    "GiniIndexTree = decision_tree_GiniIndex(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T10:42:03.714306Z",
     "start_time": "2020-07-31T10:42:03.415939Z"
    }
   },
   "outputs": [],
   "source": [
    "Prune_GiniIndex = post_pruning(GiniIndexTree, train, prune)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T03:51:30.964396Z",
     "start_time": "2020-07-31T03:51:29.286243Z"
    }
   },
   "outputs": [],
   "source": [
    "append_classifier(test, GiniIndexTree, 'Not_Pruned_GiniIndex')\n",
    "append_classifier(test, Prune_GiniIndex, 'Pruned_GiniIndex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T03:52:23.134603Z",
     "start_time": "2020-07-31T03:52:23.095707Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(test['classes'], test['Pruned_GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pruned_GiniIndex - TP: 3772, FP: 648. TP Rate = 85.34%, FP Rate = 14.66%, Accuracy = 84.42%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-31T03:59:21.403266Z",
     "start_time": "2020-07-31T03:59:21.360377Z"
    }
   },
   "outputs": [],
   "source": [
    "pd.crosstab(test['classes'], test['Not_Pruned_GiniIndex'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not_Pruned_GiniIndex - TP: 3608, FP: 661. TP Rate = 84.51%, FP Rate = 15.48%, Accuracy = 81.63%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
